{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_crawler.py\n",
    "from typing import Optional, Dict, Any, List\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import traceback\n",
    "\n",
    "from config import DATA_DIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_crawler.py\n",
    "\n",
    "from typing import Optional, Dict, Any, List, Set\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import traceback\n",
    "\n",
    "from config import DATA_DIRS\n",
    "\n",
    "class RateLimitManager:\n",
    "    def __init__(self, max_requests: int = 100, time_window: int = 60):\n",
    "        self.max_requests = max_requests\n",
    "        self.time_window = time_window\n",
    "        self.requests = []\n",
    "        self.lock = asyncio.Lock()\n",
    "\n",
    "    async def wait_if_needed(self):\n",
    "        \"\"\"Check and wait if rate limit is approaching\"\"\"\n",
    "        async with self.lock:\n",
    "            current_time = time.time()\n",
    "            self.requests = [t for t in self.requests if current_time - t < self.time_window]\n",
    "\n",
    "            if len(self.requests) >= self.max_requests * 0.8:\n",
    "                oldest_request = self.requests[0]\n",
    "                wait_time = self.time_window - (current_time - oldest_request)\n",
    "                if wait_time > 0:\n",
    "                    print(f\"Approaching rate limit. Waiting {wait_time:.2f} seconds...\")\n",
    "                    await asyncio.sleep(wait_time)\n",
    "                    self.requests = []\n",
    "\n",
    "            self.requests.append(current_time)\n",
    "\n",
    "class CivitaiImageCrawler:\n",
    "    def __init__(self, api_key: Optional[str] = None, retry_delay: int = 2):\n",
    "        self.base_url = \"https://civitai.com/api/v1\"\n",
    "        self.headers = {\"Content-Type\": \"application/json\"}\n",
    "        if api_key:\n",
    "            self.headers[\"Authorization\"] = f\"Bearer {api_key}\"\n",
    "        \n",
    "        self.retry_delay = retry_delay\n",
    "        self.rate_limiter = RateLimitManager()\n",
    "        self.logger = self._setup_logger()\n",
    "        \n",
    "        # 文件路径\n",
    "        self.images_csv = os.path.join(DATA_DIRS['csv'], 'version_images.csv')  # 改成version_images\n",
    "        self.images_json = os.path.join(DATA_DIRS['models'], 'version_images.json')  # 改成version_images\n",
    "        \n",
    "        # 加载已处理的图片ID\n",
    "        self.processed_images = set(self._load_processed_images())\n",
    "        \n",
    "        # 并发控制\n",
    "        self.semaphore = asyncio.Semaphore(5)\n",
    "\n",
    "    def _setup_logger(self):\n",
    "        \"\"\"设置日志记录器\"\"\"\n",
    "        logger = logging.getLogger('CivitaiImageCrawler')\n",
    "        logger.setLevel(logging.INFO)\n",
    "\n",
    "        if not logger.handlers:\n",
    "            # 文件处理器\n",
    "            fh = logging.FileHandler(\n",
    "                os.path.join(DATA_DIRS['logs'], f'images_crawler_{datetime.now().strftime(\"%Y%m%d\")}.log')\n",
    "            )\n",
    "            fh.setLevel(logging.INFO)\n",
    "\n",
    "            # 控制台处理器\n",
    "            ch = logging.StreamHandler()\n",
    "            ch.setLevel(logging.INFO)\n",
    "\n",
    "            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "            fh.setFormatter(formatter)\n",
    "            ch.setFormatter(formatter)\n",
    "\n",
    "            logger.addHandler(fh)\n",
    "            logger.addHandler(ch)\n",
    "\n",
    "        return logger\n",
    "\n",
    "    def _load_processed_images(self) -> Set[int]:\n",
    "        \"\"\"加载已处理的图片ID\"\"\"\n",
    "        if os.path.exists(self.images_csv):\n",
    "            try:\n",
    "                df = pd.read_csv(self.images_csv)\n",
    "                return set(df['id'].unique())\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error loading processed images: {e}\")\n",
    "        return set()\n",
    "\n",
    "    async def _make_request(self, url: str, params: Dict = None) -> Dict:\n",
    "        \"\"\"发送API请求\"\"\"\n",
    "        max_retries = 5\n",
    "        base_delay = self.retry_delay\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                async with aiohttp.ClientSession() as session:\n",
    "                    async with session.get(url, headers=self.headers, params=params) as response:\n",
    "                        if response.status == 429:  # Rate limit\n",
    "                            retry_after = response.headers.get('Retry-After', base_delay)\n",
    "                            wait_time = int(retry_after) * (2 ** attempt)\n",
    "                            self.logger.warning(f\"Rate limited. Waiting {wait_time} seconds...\")\n",
    "                            await asyncio.sleep(wait_time)\n",
    "                            continue\n",
    "\n",
    "                        response.raise_for_status()\n",
    "                        return await response.json()\n",
    "\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise\n",
    "                wait_time = base_delay * (2 ** attempt)\n",
    "                self.logger.error(f\"Request error: {e}. Retrying in {wait_time} seconds...\")\n",
    "                await asyncio.sleep(wait_time)\n",
    "\n",
    "        return None\n",
    "\n",
    "    async def collect_images_by_model_version(self, version_id: int, start_page: int = 1) -> None:\n",
    "        \"\"\"收集特定模型版本的所有图片\"\"\"\n",
    "        self.logger.info(f\"Starting to collect images for model version: {version_id}\")\n",
    "        all_images = []\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                await self.rate_limiter.wait_if_needed()\n",
    "                \n",
    "                params = {\n",
    "                    \"modelVersionId\": version_id,\n",
    "                    \"page\": start_page,\n",
    "                    \"limit\": 100,\n",
    "                    \"sort\": \"Newest\"\n",
    "                }\n",
    "                \n",
    "                response_data = await self._make_request(f\"{self.base_url}/images\", params)\n",
    "                if not response_data or 'items' not in response_data:\n",
    "                    break\n",
    "                    \n",
    "                images = response_data.get('items', [])\n",
    "                if not images:\n",
    "                    break\n",
    "                \n",
    "                # 处理图片数据\n",
    "                new_images = []\n",
    "                for img in images:\n",
    "                    if img.get('id') in self.processed_images:\n",
    "                        continue\n",
    "\n",
    "                    processed_image = {\n",
    "                        'id': img.get('id'),\n",
    "                        'url': img.get('url'),\n",
    "                        'hash': img.get('hash'),\n",
    "                        'width': img.get('width'),\n",
    "                        'height': img.get('height'),\n",
    "                        'model_version_id': version_id,\n",
    "                        'model_id': img.get('modelId'),\n",
    "                        'post_id': img.get('postId'),\n",
    "                        'nsfw': img.get('nsfw'),\n",
    "                        'nsfw_level': img.get('nsfwLevel'),\n",
    "                        'created_at': img.get('createdAt'),\n",
    "                        'cry_count': img.get('stats', {}).get('cryCount'),\n",
    "                        'laugh_count': img.get('stats', {}).get('laughCount'),\n",
    "                        'heart_count': img.get('stats', {}).get('heartCount'),\n",
    "                        'like_count': img.get('stats', {}).get('likeCount'),\n",
    "                        'comment_count': img.get('stats', {}).get('commentCount'),\n",
    "                        'username': img.get('username'),\n",
    "                        'meta': json.dumps(img.get('meta', {}))\n",
    "                    }\n",
    "                    new_images.append(processed_image)\n",
    "                    self.processed_images.add(img.get('id'))\n",
    "\n",
    "                if new_images:\n",
    "                    self._save_batch_to_csv(new_images)\n",
    "                    all_images.extend(new_images)\n",
    "                    self.logger.info(f\"Saved {len(new_images)} new images for version {version_id}\")\n",
    "                \n",
    "                metadata = response_data.get('metadata', {})\n",
    "                if not metadata.get('nextPage'):\n",
    "                    break\n",
    "                    \n",
    "                start_page += 1\n",
    "                await asyncio.sleep(1)\n",
    "\n",
    "            return all_images\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error collecting images for version {version_id}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _save_batch_to_csv(self, images: List[Dict]):\n",
    "        \"\"\"保存图片数据到CSV\"\"\"\n",
    "        if not images:\n",
    "            return\n",
    "            \n",
    "        df = pd.DataFrame(images)\n",
    "        write_header = not os.path.exists(self.images_csv)\n",
    "        df.to_csv(\n",
    "            self.images_csv,\n",
    "            mode='a',\n",
    "            header=write_header,\n",
    "            index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"主执行函数\"\"\"\n",
    "    try:\n",
    "        print(\"Starting the Civitai image crawler...\")\n",
    "\n",
    "        # 初始化爬虫\n",
    "        image_crawler = CivitaiImageCrawler()\n",
    "        \n",
    "        # 从versions.csv读取所有version_id\n",
    "        versions_csv = os.path.join(DATA_DIRS['csv'], 'all_versions.csv')\n",
    "        if not os.path.exists(versions_csv):\n",
    "            raise FileNotFoundError(\"Versions CSV file not found. Please run model crawler first.\")\n",
    "            \n",
    "        versions_df = pd.read_csv(versions_csv)\n",
    "        total_versions = len(versions_df)\n",
    "        \n",
    "        print(f\"Found {total_versions} model versions to process\")\n",
    "        \n",
    "        # 处理每个版本的图片\n",
    "        for idx, row in versions_df.iterrows():\n",
    "            version_id = row['version_id']\n",
    "            model_id = row['model_id']  # 保存model_id以便参考\n",
    "            print(f\"\\nProcessing version {version_id} of model {model_id} ({idx+1}/{total_versions})\")\n",
    "            \n",
    "            try:\n",
    "                await image_crawler.collect_images_by_model_version(version_id)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing version {version_id}: {e}\")\n",
    "                await asyncio.sleep(30)  # 错误后等待较长时间\n",
    "                continue\n",
    "                \n",
    "            # 版本之间添加延迟\n",
    "            await asyncio.sleep(2)\n",
    "\n",
    "        print(\"\\nImage crawling completed!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Critical error occurred: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置事件循环并运行\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(main())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
